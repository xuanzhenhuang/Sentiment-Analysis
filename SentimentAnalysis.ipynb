{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÊñáÊú¨ÂàÜÁ±ªÂÆû‰æã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1  ÂØºÂÖ•Áõ∏ÂÖ≥ÂåÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setp2 Âä†ËΩΩÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This film really disappointed me The acting is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I have watched this movie on and off since it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>In my opinion this movie advances no new thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>What a mess of a movie If it wasnt for Eric Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I was truly and wonderfully surprised at O Bro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                          sentences\n",
       "0       0  This film really disappointed me The acting is...\n",
       "1       0  I have watched this movie on and off since it ...\n",
       "2       0  In my opinion this movie advances no new thoug...\n",
       "3       0  What a mess of a movie If it wasnt for Eric Ro...\n",
       "4       1  I was truly and wonderfully surprised at O Bro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r'./minidatasets.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This film really disappointed me The acting is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I have watched this movie on and off since it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>In my opinion this movie advances no new thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>What a mess of a movie If it wasnt for Eric Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I was truly and wonderfully surprised at O Bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>An awful film It must have been up against som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>Two hardluck but crafty ladies decide to act l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "      <td>Well Im a few days late but what the hell Anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1</td>\n",
       "      <td>I had few problems with this film and I have h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>A very good film focusing on a very important ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                          sentences\n",
       "0          0  This film really disappointed me The acting is...\n",
       "1          0  I have watched this movie on and off since it ...\n",
       "2          0  In my opinion this movie advances no new thoug...\n",
       "3          0  What a mess of a movie If it wasnt for Eric Ro...\n",
       "4          1  I was truly and wonderfully surprised at O Bro...\n",
       "...      ...                                                ...\n",
       "4995       0  An awful film It must have been up against som...\n",
       "4996       1  Two hardluck but crafty ladies decide to act l...\n",
       "4997       1  Well Im a few days late but what the hell Anyw...\n",
       "4998       1  I had few problems with this film and I have h...\n",
       "4999       1  A very good film focusing on a very important ...\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 ÂàõÂª∫ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv('./minidatasets.csv')\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]['sentences'], self.data.iloc[index]['labels']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This film really disappointed me The acting is atrocious Unbelievable And its about actors The story is incredibly obvious A group of independent actors stage a Passion Play and in turn they start to live out the lives of the characters they play Ive been watching a lot of movies lately thanks to Netflix and this is the first one I havent watched all the way through in a long time I felt I didnt need to see the end we all know the end of this story For some it seems this modernization of the Gospels is either sacrilegious or enlightening I cannot speak to any of this as I wasnt raised in the Christian church That being said I was raised in the US and I live in an increasingly Christian culture Im curious enough about Jesus and about the modernization of the religion for better or worse I havent seen Mel Gibsons version but Im guessing that those who liked that one will like this except for the most conservative I just wish this was a better film Lots of these reviews praise Arcands direction and especially the cinematography I liked neither The film itself is rather prudish and preachy I didnt believe the characters personae and I was never involved with their on screen lives The play within the play is very much dated and would not I think carry its own weight in a real time production But thats beside the point What I really needed for this to work would have been stronger development of the characters and the plot to support the philosophical and theological questions the film would like to be about And the musical choices are obvious and unoriginal There were two examples of this that come easily to mind Firstly there is a reenactment of the parable of Jesus driving the money lenders from the temple the lead actor who has fallen for the woman who will play Magdalene and who is also a model and dancer becomes enraged that she must debase herself by auditioning for a commercial with a wicked producer and plenty of panting men in the audience with her pants off He trashes the place and chases them all out I guess this is the level that the film wishes to reach The romance between these two is entirely arbitrary and not at all emotionally realized and the scene is played out like a highschool rendering of Death of a Salesman ie not well Please stop hitting me over the head with this highhanded significance The other is the relationship between the other female lead and the priest who has asked them to do the play and who eventually turns against them and betrays them to the nowadayscorrupt Church Why Why does she sleep with this guy It brings him so much pleasure and me so little pain Ah the saintly whore and the lovable old coot It seems to be just enough for Arcand to signify but not worth the trouble to enrich and enliven these characters They are going through the motions and Im reaching for the eject button Feel free to write me off as bored jaded or just not interested Feel free to watch this movie and see the Passion in all its beauty sadness and inspiration delivered as an amateurish and gimmicky charade Feel free to have all your preconceived ideas affirmed and see any shred of artistic integrity forsaken for monotonous drivel But dont say I didnt warn you', 0)\n",
      "('I have watched this movie on and off since it started playing about 1 hour ago and i have to say thats an hour of my life i wasted and will not be getting back The acting is crap and the scripts need a serious look at and whoever wrote them needs to be slapped perhaps the TV will explode and put me out of my misery The only good thing about this movie is that for guys and girls it has some good eye candy in it though most of which i wish would disappear as far as the movie is concerned the special effects as sht Dante who thinks a guy dressed in skin tight leather pants and half a leather jacket is scary he looks more feminine than most of the women in this movie the voice of Dante is pathetic nobody finds it threatening or scary AT ALL please TV i beg you to blow up', 0)\n",
      "('In my opinion this movie advances no new thought seems to me like taking a spear to a spear without looking to the side the director seems to have an agenda Duh I find that his rational is lacking there does not seem to be room for the alternative view I for one am usually on the side of the naysayer but this movie lacks credibility as it relies on the fantastic observations of the manwoman on the street really now if you wish to cr5eate a credible alternative to a creed held onto for 2000 years you have got to make more of an effort allowing the other side to voice their beliefs Im not sure but at the beginning of the movie it felt like an attack on the Cristian faith I for one am a non believer but allow for the beliefs of others and would not wish no ridicule them but try to understand and tolerate', 0)\n",
      "('What a mess of a movie If it wasnt for Eric Roberts and Susan Sarandons performances this movie would be a total waste A very muddled plot and phony dialogueEric Roberts debutwhere did his career go from this movie onNowhere but down', 0)\n",
      "('I was truly and wonderfully surprised at O Brother Where Art Thou The video store was out of all the movies I was planning on renting so then I came across this I came home and as I watched I became engrossed and found myself laughing out loud The Coens have made a magnificiant film again But I think the first time you watch this movie you get to know the characters The second time now that you know them you laugh sooo hard it could hurt you I strongly would reccomend ANYONE seeing this because if you are not you are truly missing a film gem for the ages 1010', 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset()\n",
    "for i in range(5):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 ÂàíÂàÜÊï∞ÊçÆÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "trainset, validset = random_split(dataset, lengths=[0.8,0.2])\n",
    "print(len(trainset), len(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3358\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for i in range(30):\n",
    "    if len(trainset[i][0]) > max:\n",
    "        max = len(trainset[i][0])\n",
    "    # print(len(trainset[i][0]))\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 ÂàõÂª∫Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def collate_func(batch):\n",
    "    # sentences = [x[0] for x in batch]\n",
    "    # labels = [x[1] for x in batch]\n",
    "    sentences, labels = [],[]\n",
    "    for item in batch:\n",
    "        sentences.append(item[0])\n",
    "        labels.append(item[1])\n",
    "    inputs = tokenizer(sentences, max_length=250, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "    inputs['labels'] = torch.tensor(labels)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=12, shuffle=True,collate_fn=collate_func)\n",
    "validloader = DataLoader(validset, batch_size=24, shuffle=False,collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2147,  ...,     0,     0,     0],\n",
       "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
       "        [  101,  2060,  4391,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2023,  6789,  ...,     0,     0,     0],\n",
       "        [  101,  7186,  2003,  ...,  2006,  2279,   102],\n",
       "        [  101,  2064, 10334,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerate(trainloader))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 ÂàõÂª∫Ê®°ÂûãÂèä‰ºòÂåñÂô®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ÈªÑÈìâÂú≥\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 ËÆ≠ÁªÉ‰∏éÈ™åËØÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in validloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k:v.cuda() for k,v in batch.items()}\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits,dim=-1)\n",
    "            acc_num += (pred.long() == batch['labels'].long()).float().sum()\n",
    "    return acc_num / len(validset)\n",
    "\n",
    "def train(epoch = 3 ,log_step = 50):\n",
    "    global_step = 0\n",
    "    print('start training...')\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k:v.cuda() for k,v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "            if global_step % log_step == 0:\n",
    "                print(f'epoch:{ep}, global_step:{global_step}, loss:{output.loss.item()}')\n",
    "            global_step += 1\n",
    "        acc = evaluate()\n",
    "        print(f'epoch:{ep}, acc:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 Ê®°ÂûãËÆ≠ÁªÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "epoch:0, global_step:0, loss:0.6901788115501404\n",
      "epoch:0, global_step:50, loss:0.4988901913166046\n",
      "epoch:0, global_step:100, loss:0.2911245822906494\n",
      "epoch:0, global_step:150, loss:0.4980738162994385\n",
      "epoch:0, global_step:200, loss:0.21487300097942352\n",
      "epoch:0, global_step:250, loss:0.315349817276001\n",
      "epoch:0, global_step:300, loss:0.38117292523384094\n",
      "epoch:0, acc:0.89000004529953\n",
      "epoch:1, global_step:350, loss:0.10887125879526138\n",
      "epoch:1, global_step:400, loss:0.16925925016403198\n",
      "epoch:1, global_step:450, loss:0.02929655648767948\n",
      "epoch:1, global_step:500, loss:0.04900970682501793\n",
      "epoch:1, global_step:550, loss:0.048804908990859985\n",
      "epoch:1, global_step:600, loss:0.13585416972637177\n",
      "epoch:1, global_step:650, loss:0.029725665226578712\n",
      "epoch:1, acc:0.8390000462532043\n",
      "epoch:2, global_step:700, loss:0.19784528017044067\n",
      "epoch:2, global_step:750, loss:0.015416477806866169\n",
      "epoch:2, global_step:800, loss:0.009625358507037163\n",
      "epoch:2, global_step:850, loss:0.06888013333082199\n",
      "epoch:2, global_step:900, loss:0.06921566277742386\n",
      "epoch:2, global_step:950, loss:0.012964856810867786\n",
      "epoch:2, global_step:1000, loss:0.010907757095992565\n",
      "epoch:2, acc:0.8890000581741333\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step9 Ê®°ÂûãÈ¢ÑÊµã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËæìÂÖ•ÔºöIt is so comically small and the flowers are very dead looking. Definitely not the pop of color that I was hoping for.\n",
      "Ê®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºönegative\n"
     ]
    }
   ],
   "source": [
    "sen = \"It is so comically small and the flowers are very dead looking. Definitely not the pop of color that I was hoping for.\"\n",
    "id2_label = {0:'negative',1:'positive'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt',max_length=250, padding=\"max_length\", truncation=True)\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits,dim=-1)\n",
    "    print(f\"ËæìÂÖ•Ôºö{sen}\\nÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºö{id2_label.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËæìÂÖ•ÔºöLet me start by saying this is the first time I encounter this problem with building adult Lego sets as a collector. I purchased two of these boxes and both have the same issue. The pieces, when it comes to creating the branches with the gray and brown bits, aren‚Äôt gripping the branches so the blossoms keep falling out whenever I pick it up or it‚Äôs moved to the side. It‚Äôs made this experience extremely frustrating overall. If it was just one of the boxes then I‚Äôd chalk it up to just a faulty box but both boxes resulted in the same issues üò¢ I believe there‚Äôs an issue with these pieces.\n",
      "Ê®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºönegative\n"
     ]
    }
   ],
   "source": [
    "sen = \"Let me start by saying this is the first time I encounter this problem with building adult Lego sets as a collector. I purchased two of these boxes and both have the same issue. The pieces, when it comes to creating the branches with the gray and brown bits, aren‚Äôt gripping the branches so the blossoms keep falling out whenever I pick it up or it‚Äôs moved to the side. It‚Äôs made this experience extremely frustrating overall. If it was just one of the boxes then I‚Äôd chalk it up to just a faulty box but both boxes resulted in the same issues üò¢ I believe there‚Äôs an issue with these pieces.\"\n",
    "id2_label = {0:'negative',1:'positive'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt',max_length=250, padding=\"max_length\", truncation=True)\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits,dim=-1)\n",
    "    print(f\"ËæìÂÖ•Ôºö{sen}\\nÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºö{id2_label.get(pred.item())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËæìÂÖ•Ôºöi like this lego set but i had a lot of pieces missing\n",
      "Ê®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºönegative\n"
     ]
    }
   ],
   "source": [
    "sen = \"i like this lego set but i had a lot of pieces missing\"\n",
    "id2_label = {0:'negative',1:'positive'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt',max_length=250, padding=\"max_length\", truncation=True)\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits,dim=-1)\n",
    "    print(f\"ËæìÂÖ•Ôºö{sen}\\nÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºö{id2_label.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËæìÂÖ•ÔºöI enjoy the Botanicals, but the Lupin was frustrating to build and fell apart easily. I threw those 2 stems back in the bag.\n",
      "Ê®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºönegative\n"
     ]
    }
   ],
   "source": [
    "sen = \"I enjoy the Botanicals, but the Lupin was frustrating to build and fell apart easily. I threw those 2 stems back in the bag.\"\n",
    "id2_label = {0:'negative',1:'positive'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt',max_length=250, padding=\"max_length\", truncation=True)\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits,dim=-1)\n",
    "    print(f\"ËæìÂÖ•Ôºö{sen}\\nÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºö{id2_label.get(pred.item())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËæìÂÖ•ÔºöI got this for my 7 year old thinking this will be challenging as it is 18+. But this was probably one of the easiest ones to build, he says this should probably be 5+. Not worth the money. He does find the 9+, 10+ Technic car more challenging and more enjoyable to build. This was just not worth it for the money. Definitely not a 18+ product\n",
      "Ê®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºönegative\n"
     ]
    }
   ],
   "source": [
    "sen = \"I got this for my 7 year old thinking this will be challenging as it is 18+. But this was probably one of the easiest ones to build, he says this should probably be 5+. Not worth the money. He does find the 9+, 10+ Technic car more challenging and more enjoyable to build. This was just not worth it for the money. Definitely not a 18+ product\"\n",
    "id2_label = {0:'negative',1:'positive'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt',max_length=250, padding=\"max_length\", truncation=True)\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits,dim=-1)\n",
    "    print(f\"ËæìÂÖ•Ôºö{sen}\\nÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºö{id2_label.get(pred.item())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËæìÂÖ•ÔºöI purchased and assembled the set as a Mother's Day gift for my mom who loves flowers. I wanted to do something a little different and last longer. Overall great experience, make sure you have a big space to spread out pieces since they are wicked small. One con I had I wish the picture instructions showed more detail when similar pieces had to be flipped a certain way\n",
      "Ê®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºöpositive\n"
     ]
    }
   ],
   "source": [
    "sen = \"I purchased and assembled the set as a Mother's Day gift for my mom who loves flowers. I wanted to do something a little different and last longer. Overall great experience, make sure you have a big space to spread out pieces since they are wicked small. One con I had I wish the picture instructions showed more detail when similar pieces had to be flipped a certain way\"\n",
    "id2_label = {0:'negative',1:'positive'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt',max_length=250, padding=\"max_length\", truncation=True)\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits,dim=-1)\n",
    "    print(f\"ËæìÂÖ•Ôºö{sen}\\nÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºö{id2_label.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËæìÂÖ•ÔºöMaybe I was swayed too much by the enthusiastic reviews, but I didn't find the wild robot as coherent and deep as some reviewers made it out to be.Seeing the first HowToTrainYourDragon (one of my favourite movies) of all time was written by the same guy , and the trailer seemed to touch upon some admittedly deep topics, I thought this movie would follow suit.But on most levels, I have to admit it was a surprisingly flat experience, not bad by any metric, but surely below expectations. The first 20 minutes are beautiful, but a bit slow and don't seem to establish much of a plot, the film peaks at around halfway with some strong emotional beats, but ultimately disappoints in a safe and predictable third act.\n",
      "Ê®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºönegative\n"
     ]
    }
   ],
   "source": [
    "sen = \"Maybe I was swayed too much by the enthusiastic reviews, but I didn't find the wild robot as coherent and deep as some reviewers made it out to be.Seeing the first HowToTrainYourDragon (one of my favourite movies) of all time was written by the same guy , and the trailer seemed to touch upon some admittedly deep topics, I thought this movie would follow suit.But on most levels, I have to admit it was a surprisingly flat experience, not bad by any metric, but surely below expectations. The first 20 minutes are beautiful, but a bit slow and don't seem to establish much of a plot, the film peaks at around halfway with some strong emotional beats, but ultimately disappoints in a safe and predictable third act.\"\n",
    "id2_label = {0:'negative',1:'positive'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt',max_length=250, padding=\"max_length\", truncation=True)\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits,dim=-1)\n",
    "    print(f\"ËæìÂÖ•Ôºö{sen}\\nÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºö{id2_label.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËæìÂÖ•ÔºöI generally liked the animation but it constantly reminded me of trying to watch a 3D movie without the 3D glasses. The petty drama is endless and becomes old fast. There are loads of action scenes that immediately devolve into slow soap opera drama. My wife and I kept nodding off during these whine-a-thones which seemed very contrived. I did like all of the iterations of spider flavors in the Spiderverse which were endlessly creative and entertaining. The music always suggests exciting action scenes but this becomes a little exhausting after the 4th or 5th wind up. Long winded exposition seems necessary to spoon feed a very lengthy and convoluted plot. When I booked I noticed the theater was sold out but we left before the end and noticed that only 10 members of the audience still remained having left before us. Spot was a good albeit comedic villain. I would suggest going just for the animation and humor even with the 140min run time.\n",
      "Ê®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºönegative\n"
     ]
    }
   ],
   "source": [
    "sen = \"I generally liked the animation but it constantly reminded me of trying to watch a 3D movie without the 3D glasses. The petty drama is endless and becomes old fast. There are loads of action scenes that immediately devolve into slow soap opera drama. My wife and I kept nodding off during these whine-a-thones which seemed very contrived. I did like all of the iterations of spider flavors in the Spiderverse which were endlessly creative and entertaining. The music always suggests exciting action scenes but this becomes a little exhausting after the 4th or 5th wind up. Long winded exposition seems necessary to spoon feed a very lengthy and convoluted plot. When I booked I noticed the theater was sold out but we left before the end and noticed that only 10 members of the audience still remained having left before us. Spot was a good albeit comedic villain. I would suggest going just for the animation and humor even with the 140min run time.\"\n",
    "id2_label = {0:'negative',1:'positive'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt',max_length=250, padding=\"max_length\", truncation=True)\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits,dim=-1)\n",
    "    print(f\"ËæìÂÖ•Ôºö{sen}\\nÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÔºö{id2_label.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step10 ÊñáÊú¨ÊëòË¶ÅÊ®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\"\n",
    "I got this Lego set as a gift, and haven't built with Legos in literal years. When the botanical sets started I knew I had to have them!\n",
    " This is my first build in the botanical set and I have roughly 8 more sets to go. This was easy for a beginner, the instructions were very clear.\n",
    "   I had one flower I had a little trouble with, but it took no longer than 5 minutes to figure out what I was doing wrong to fix it. Didn't take away from the building experience at all! Overall,\n",
    "     I'd recommend this set for the Lego and Flower lover in your life!\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=30, min_length=10, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\"\n",
    "The LEGO Wildflower Bouquet is a new concept that allows for flowers to be put into a home with an intention of not having them die out over time!\n",
    " The aesthetics of the bouquet design are beautiful, bearing fantastic detail and color combinations such that they almost look like real wild flowers. \n",
    " The build process is fun and quite easy and therefore this project suits both serious LEGO followers and casual builders. It looks amazing as a decoration piece, \n",
    " which is what it is meant for and it is sure to add all the fun you need into any room while maintaining simplicity.\n",
    "A wonderful idea for a present or just a fun decoration to make yourself!I'd recommend this set for the Lego and Flower lover in your life!\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=50, min_length=10, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\"\n",
    "I purchased and assembled the set as a Mother's Day gift for my mom who loves flowers. I wanted to do something a little different and last longer.\n",
    " Overall great experience, make sure you have a big space to spread out pieces since they are wicked small.\n",
    "   One con I had I wish the picture instructions showed more detail when similar pieces had to be flipped a certain way\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=50, min_length=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
